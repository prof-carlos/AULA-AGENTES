"""
App: Planejador de Viagens com LangGraph (com fallback headless)

Corre√ß√£o aplicada: o erro `ModuleNotFoundError: No module named 'streamlit'` ocorre quando o
Streamlit n√£o est√° instalado/indispon√≠vel. Este arquivo agora:
- Usa Streamlit **se dispon√≠vel** (UI completa).
- Cai para um **modo CLI/headless** quando Streamlit n√£o est√° presente.
- Inclui um **LLM de fallback** (DummyLLM) se `langchain_groq`/`GROQ_API_KEY` n√£o estiverem dispon√≠veis.
- Adiciona **testes embutidos** execut√°veis com `RUN_TESTS=1 python app.py`.

Como executar (UI):
  pip install streamlit langgraph langchain-core langchain-groq
  export GROQ_API_KEY=...  # ou informe no campo da UI
  streamlit run app.py

Como executar (headless/CLI):
  # sem streamlit instalado, roda em modo texto
  python app.py
  # ou com vari√°veis de ambiente para n√£o interagir:
  DESTINO="Lisboa, Portugal" DATA_INICIO=2025-01-01 DATA_FIM=2025-01-05 ORCAMENTO="R$ 5.000" PREFERENCIAS="museus" python app.py

Como rodar os testes internos:
  RUN_TESTS=1 python app.py
"""

from __future__ import annotations

import os
import sys
from datetime import date, datetime, timedelta
from typing import Any, TypedDict

# ==========================
# Imports opcionais (com fallback)
# ==========================
try:  # Streamlit pode n√£o estar instalado no ambiente
    import streamlit as _st
    st = _st
    STREAMLIT_AVAILABLE = True
except ModuleNotFoundError:
    st = None
    STREAMLIT_AVAILABLE = False

try:  # LangChain - mensagens
    from langchain_core.messages import SystemMessage, HumanMessage
except Exception:  # fallback m√≠nimo para rodar sem langchain_core
    class _Msg:  # type: ignore
        def __init__(self, content: str):
            self.content = content
    SystemMessage = HumanMessage = _Msg  # type: ignore

try:  # Groq LLM (opcional)
    from langchain_groq import ChatGroq
except Exception:
    ChatGroq = None  # type: ignore

# LangGraph √© obrigat√≥rio para o grafo
try:
    from langgraph.graph import StateGraph, END
except Exception as e:  # falha dura, mas com mensagem clara
    raise RuntimeError(
        "LangGraph √© necess√°rio. Instale com: pip install langgraph"
    ) from e

# ==========================
# Estado do grafo
# ==========================
class TripState(TypedDict, total=False):
    destino: str
    data_inicio: str
    data_fim: str
    orcamento: str
    preferencias: str

    plan: str
    hotels: str
    leisure: str
    food: str
    final: str

# ==========================
# Utilidades
# ==========================

def _parse_date(d: Any) -> date:
    if isinstance(d, date) and not isinstance(d, datetime):
        return d
    if isinstance(d, datetime):
        return d.date()
    # tenta ISO
    return datetime.fromisoformat(str(d)).date()


def validate_inputs(destino: str, data_inicio: Any, data_fim: Any) -> tuple[bool, str | None]:
    if not destino or not str(destino).strip():
        return False, "Por favor, informe o destino."
    try:
        d0 = _parse_date(data_inicio)
        d1 = _parse_date(data_fim)
    except Exception:
        return False, "Datas inv√°lidas: use formato ISO AAAA-MM-DD."
    if d1 < d0:
        return False, "A data de t√©rmino deve ser posterior √† data de in√≠cio."
    return True, None

# ==========================
# Fallback LLM (quando Groq/LLM real indispon√≠vel)
# ==========================
class _DummyResp:
    def __init__(self, content: str):
        self.content = content


class DummyLLM:
    """LLM simples para ambientes offline/teste.
    Gera conte√∫do sint√©tico, mas com estrutura esperada pelas tarefas.
    """

    def __init__(self, temperature: float = 0.0):
        self.temperature = temperature

    def invoke(self, messages: list[Any]) -> _DummyResp:
        prompt = "\n\n".join(getattr(m, "content", str(m)) for m in messages)
        if "HOSPEDAGEM" in prompt.upper() and "TABELA" in prompt.upper():
            return _DummyResp(
                """
| Nome | Endere√ßo | Site | Telefone |
| --- | --- | --- | --- |
| Hotel Central | Rua A, 123 | https://hotelcentral.example | +351 21 000 000 |
| Boutique Vista | Av. B, 456 | https://boutiquevista.example | +351 21 111 111 |
| Porto Inn | Rua C, 789 | https://portoinn.example | +351 21 222 222 |

**Fontes**: [Turismo Local](https://turismo.local), [Guias Exemplo](https://guia.exemplo)
                """.strip()
            )
        if "LAZER" in prompt.upper():
            return _DummyResp(
                """
- Castelo Hist√≥rico ‚Äî Panorama da cidade. <https://castelo.example>
- Museu de Arte ‚Äî Cole√ß√µes modernas. <https://museu.example>
- Mercado Central ‚Äî Gastronomia local. <https://mercado.example>

**Eventos (per√≠odo)**
- Festival de Ver√£o ‚Äî M√∫sica ao ar livre. <https://festival.example>
- Feira de Livros ‚Äî Autores locais. <https://feira.example>

**Fontes**: [Agenda Cultural](https://agenda.example)
                """.strip()
            )
        if "ALIMENTA√á√ÉO" in prompt.upper():
            return _DummyResp(
                """
| Nome | Bairro | Faixa de Pre√ßo | Cozinha | Site |
| --- | --- | --- | --- | --- |
| Tasca do Bairro | Centro | $$ | Portuguesa | https://tasca.example |
| Mar & Brasa | Ribeira | $$$ | Peixes e grelhados | https://marebrasa.example |

**Comidas t√≠picas**: Bacalhau √† Br√°s, Pastel de Nata, Caldo Verde, Francesinha.

**Fontes**: [Guia Gastron√¥mico](https://gastronomia.example)
                """.strip()
            )
        if "RELAT√ìRIO FINAL" in prompt.upper():
            return _DummyResp(
                ("Introdu√ß√£o: Este roteiro sintetiza op√ß√µes de hospedagem, lazer e alimenta√ß√£o "
                 "para uma experi√™ncia equilibrada.\n\n"
                 "Hospedagem: ver tabela acima.\n\nLazer: destaques culturais e eventos no per√≠odo.\n\n"
                 "Alimenta√ß√£o: restaurantes recomendados e comidas t√≠picas.\n\n"
                 "Mini-roteiro: Dia 1 ‚Äî centro hist√≥rico; Dia 2 ‚Äî museus; Dia 3 ‚Äî orla.\n\n"
                 "Dicas r√°pidas: compre bilhetes antecipados; use transporte p√∫blico; aten√ß√£o a pertences.\n\n"
                 "Fontes: consolidadas ao final das se√ß√µes.")
            )
        # Planejamento geral
        return _DummyResp(
            """
1) HOSPEDAGEM ‚Äî Selecionar hot√©is bem localizados e com bom custo-benef√≠cio.
2) LAZER ‚Äî Mapear atra√ß√µes essenciais e eventos no per√≠odo.
3) ALIMENTA√á√ÉO ‚Äî Levantar restaurantes e comidas t√≠picas.

**Crit√©rios**
- Proximidade a transporte/centro
- Avalia√ß√µes consistentes
- Adequa√ß√£o ao or√ßamento/prefer√™ncias
- Variedade de experi√™ncias

Justificativa: o recorte em 3 pilares organiza a pesquisa e facilita decis√µes.
            """.strip()
        )

# ==========================
# LLM Factory (com cache quando Streamlit existir)
# ==========================

def _get_llm_impl(api_key: str | None, temperature: float = 0.2):
    key = api_key or os.environ.get("GROQ_API_KEY")
    if ChatGroq and key:
        return ChatGroq(api_key=key, model_name="llama-3.3-70b-versatile", temperature=temperature)
    # fallback
    return DummyLLM(temperature=temperature)


if STREAMLIT_AVAILABLE:
    @st.cache_resource(show_spinner=False)
    def get_llm(api_key: str | None, temperature: float = 0.2):
        return _get_llm_impl(api_key, temperature)
else:
    def get_llm(api_key: str | None, temperature: float = 0.2):  # type: ignore
        return _get_llm_impl(api_key, temperature)

# ==========================
# N√≥s do grafo (LangGraph)
# ==========================

def make_planner_node(llm: Any):
    def node(state: TripState) -> dict:
        system = "Voc√™ estrutura planos objetivos e pr√°ticos em 3 passos fixos."
        human = f"""
PLANEJAMENTO GERAL\n
Destino: {state['destino']}\n
Datas: {state['data_inicio']} a {state['data_fim']}\n
Or√ßamento: {state['orcamento']}\n
Prefer√™ncias: {state['preferencias']}\n
\n
Sua fun√ß√£o: **Roteirista de Viagens**.\n
Objetivo: Gerar um plano de pesquisa dividido em **EXATAMENTE 3 subtarefas numeradas**:\n
1) HOSPEDAGEM; 2) LAZER; 3) ALIMENTA√á√ÉO.\n
\n
Regras de sa√≠da (em Markdown):\n
- Liste as 3 subtarefas numeradas (cada uma com 1 frase).\n
- Em seguida, traga 3‚Äì5 crit√©rios de sele√ß√£o (bullets) considerando or√ßamento e prefer√™ncias.\n
- Feche com 1‚Äì2 linhas de justificativa.\n
Retorne **somente** esse conte√∫do.
"""
        resp = get_llm(None).invoke([SystemMessage(content=system), HumanMessage(content=human)])
        return {"plan": resp.content}

    return node


def make_hotels_node(llm: Any):
    def node(state: TripState) -> dict:
        system = "Voc√™ verifica informa√ß√µes de hot√©is e organiza dados de contato."
        human = f"""
HOSPEDAGEM\n
Destino: {state['destino']}\n
Per√≠odo: {state['data_inicio']} ‚Äì {state['data_fim']}\n
Or√ßamento: {state['orcamento']}\n
Prefer√™ncias: {state['preferencias']}\n
Plano do roteirista:\n
{state.get('plan','')}\n
\n
Entregue uma **tabela Markdown** com as colunas: **Nome | Endere√ßo | Site | Telefone**.\n
Inclua **5‚Äì8 op√ß√µes** e **2‚Äì4 fontes** (t√≠tulo + URL) ao final.
"""
        resp = get_llm(None).invoke([SystemMessage(content=system), HumanMessage(content=human)])
        return {"hotels": resp.content}

    return node


def make_leisure_node(llm: Any):
    def node(state: TripState) -> dict:
        system = "Voc√™ encontra atra√ß√µes e eventos relevantes √†s datas."
        human = f"""
LAZER\n
Destino: {state['destino']}\n
Per√≠odo: {state['data_inicio']} ‚Äì {state['data_fim']}\n
Plano do roteirista:\n
{state.get('plan','')}\n
\n
Liste **8‚Äì12 pontos tur√≠sticos essenciais** (com breve descri√ß√£o e link).\n
Depois, **3‚Äì5 eventos** que ocorram no per√≠odo informado (com breve descri√ß√£o e link).\n
Formate em listas e finalize com **2‚Äì4 fontes** (t√≠tulo + URL).
"""
        resp = get_llm(None).invoke([SystemMessage(content=system), HumanMessage(content=human)])
        return {"leisure": resp.content}

    return node


def make_food_node(llm: Any):
    def node(state: TripState) -> dict:
        system = "Voc√™ conhece a cena gastron√¥mica e as especialidades locais."
        human = f"""
ALIMENTA√á√ÉO\n
Destino: {state['destino']}\n
Prefer√™ncias: {state['preferencias']}\n
Plano do roteirista:\n
{state.get('plan','')}\n
\n
1) Recomende **8‚Äì12 restaurantes** (\n
   entregue em **tabela Markdown** com **Nome | Bairro | Faixa de Pre√ßo | Cozinha | Site**).\n
2) Liste **5‚Äì8 comidas t√≠picas** com breve explica√ß√£o.\n
Finalize com **2‚Äì4 fontes** (t√≠tulo + URL).
"""
        resp = get_llm(None).invoke([SystemMessage(content=system), HumanMessage(content=human)])
        return {"food": resp.content}

    return node


def make_writer_node(llm: Any):
    def node(state: TripState) -> dict:
        system = "Voc√™ escreve de forma clara, did√°tica e organizada."
        human = f"""
RELAT√ìRIO FINAL\n
Use o plano (PLANEJAMENTO) e as entregas de HOSPEDAGEM, LAZER e ALIMENTA√á√ÉO para compor o texto final **(500‚Äì700 palavras)**.\n
Inclua:\n
- Introdu√ß√£o breve;\n
- Se√ß√µes: **Hospedagem**, **Lazer**, **Alimenta√ß√£o** (incorpore tabelas/listas quando aplic√°vel);\n
- Mini-roteiro sugerido **por dia** (alto n√≠vel);\n
- **Dicas r√°pidas** (transporte/seguran√ßa);\n
- Se√ß√£o **Fontes** consolidada.\n
\n
Contexto:\n
- Destino: {state['destino']}\n
- Datas: {state['data_inicio']} a {state['data_fim']}\n
- Or√ßamento: {state['orcamento']}\n
- Prefer√™ncias: {state['preferencias']}\n
\n
=== PLANEJAMENTO ===\n
{state.get('plan','')}\n
\n
=== HOSPEDAGEM ===\n
{state.get('hotels','')}\n
\n
=== LAZER ===\n
{state.get('leisure','')}\n
\n
=== ALIMENTA√á√ÉO ===\n
{state.get('food','')}
"""
        resp = get_llm(None).invoke([SystemMessage(content=system), HumanMessage(content=human)])
        return {"final": resp.content}

    return node

# ==========================
# Builder do grafo
# ==========================

def build_graph(llm: Any) -> Any:
    builder = StateGraph(TripState)
    builder.add_node("planner", make_planner_node(llm))
    builder.add_node("hotels", make_hotels_node(llm))
    builder.add_node("leisure", make_leisure_node(llm))
    builder.add_node("food", make_food_node(llm))
    builder.add_node("writer", make_writer_node(llm))

    builder.set_entry_point("planner")
    builder.add_edge("planner", "hotels")
    builder.add_edge("hotels", "leisure")
    builder.add_edge("leisure", "food")
    builder.add_edge("food", "writer")
    builder.add_edge("writer", END)

    return builder.compile()

# ==========================
# UI Streamlit (executada somente se Streamlit existir)
# ==========================
if STREAMLIT_AVAILABLE:
    st.set_page_config(page_title="Agentes de Viagem IA (LangGraph)", page_icon="üß≠", layout="wide")
    st.title("üß≠ Planejador de Viagens com LangGraph")
    st.markdown(
        """
Forne√ßa os detalhes da sua viagem e deixe nossa **graph** de n√≥s especializados criar um roteiro completo para voc√™.
Os n√≥s pesquisam hospedagem, lazer, gastronomia e consolidam tudo em um relat√≥rio final.
"""
    )
    st.divider()

    with st.form("travel_planner_form"):
        st.subheader("Preencha os dados da sua viagem:")
        col1, col2 = st.columns(2)
        with col1:
            destino = st.text_input("Destino (cidade, pa√≠s)", placeholder="Ex.: Lisboa, Portugal")
            data_inicio = st.date_input("Data de in√≠cio", value=date.today())
        with col2:
            orcamento = st.text_input("Or√ßamento aproximado (opcional)", placeholder="Ex.: R$ 5.000 no total")
            data_fim = st.date_input("Data de t√©rmino", value=date.today() + timedelta(days=7))

        preferencias = st.text_area(
            "Prefer√™ncias e observa√ß√µes (opcional)",
            placeholder=(
                "Ex: Gosto de museus e bairros hist√≥ricos. Prefiro hot√©is boutique. "
                "Tenho restri√ß√£o a gl√∫ten."
            ),
        )

        st.markdown("---")
        col_api_1, col_api_2 = st.columns([2, 1])
        with col_api_1:
            api_key_input = st.text_input(
                "GROQ API Key (opcional ‚Äî se ausente, usa vari√°vel de ambiente GROQ_API_KEY)",
                type="password",
            )
        with col_api_2:
            temperatura = st.slider("Temperatura", 0.0, 1.0, 0.2, 0.05)

        executar = st.form_submit_button("Gerar Roteiro de Viagem", use_container_width=True)

    if executar:
        ok, msg = validate_inputs(destino, data_inicio, data_fim)
        if not ok:
            st.error(msg)
            st.stop()

        llm = get_llm(api_key_input, temperature=temperatura)
        graph = build_graph(llm)

        with st.spinner(
            "Planejando sua viagem com LangGraph... Montando plano, hospedagem, lazer, alimenta√ß√£o e relat√≥rio final."
        ):
            final_state: TripState = graph.invoke(
                {
                    "destino": destino,
                    "data_inicio": str(data_inicio),
                    "data_fim": str(data_fim),
                    "orcamento": orcamento or "n√£o informado",
                    "preferencias": preferencias or "n√£o informado",
                }
            )

        st.success("Seu roteiro de viagem est√° pronto! ‚úÖ")
        aba_plano, aba_hosp, aba_alim, aba_lazer, aba_final = st.tabs(
            ["üìã Planejamento", "üè® Hospedagem", "üçΩÔ∏è Alimenta√ß√£o", "üé≠ Lazer", "‚ú® Relat√≥rio Final"]
        )
        with aba_plano:
            st.subheader("Plano de A√ß√£o dos N√≥s")
            st.markdown(final_state.get("plan", ""))
        with aba_hosp:
            st.subheader("Pesquisa de Hospedagem")
            st.markdown(final_state.get("hotels", ""))
        with aba_alim:
            st.subheader("Recomenda√ß√µes Gastron√¥micas")
            st.markdown(final_state.get("food", ""))
        with aba_lazer:
            st.subheader("Sugest√µes de Lazer e Eventos")
            st.markdown(final_state.get("leisure", ""))
        with aba_final:
            st.subheader("Seu Roteiro de Viagem Personalizado")
            st.markdown(final_state.get("final", ""))

# ==========================
# CLI / Headless fallback (sem Streamlit)
# ==========================

def run_cli() -> None:
    print("[Modo CLI] Streamlit n√£o detectado ‚Äî rodando em modo texto.\n")
    destino = os.environ.get("DESTINO") or input("Destino (cidade, pa√≠s): ").strip()
    data_inicio = os.environ.get("DATA_INICIO") or input("Data de in√≠cio (AAAA-MM-DD): ").strip()
    data_fim = os.environ.get("DATA_FIM") or input("Data de t√©rmino (AAAA-MM-DD): ").strip()
    orcamento = os.environ.get("ORCAMENTO", "n√£o informado")
    preferencias = os.environ.get("PREFERENCIAS", "n√£o informado")

    ok, msg = validate_inputs(destino, data_inicio, data_fim)
    if not ok:
        print(f"Erro: {msg}")
        sys.exit(2)

    temperatura = float(os.environ.get("TEMPERATURA", "0.2"))
    api_key = os.environ.get("GROQ_API_KEY")  # opcional
    llm = get_llm(api_key, temperature=temperatura)
    graph = build_graph(llm)

    final_state: TripState = graph.invoke(
        {
            "destino": destino,
            "data_inicio": str(data_inicio),
            "data_fim": str(data_fim),
            "orcamento": orcamento,
            "preferencias": preferencias,
        }
    )

    print("\n=== üìã PLANEJAMENTO ===\n")
    print(final_state.get("plan", ""))
    print("\n=== üè® HOSPEDAGEM ===\n")
    print(final_state.get("hotels", ""))
    print("\n=== üé≠ LAZER ===\n")
    print(final_state.get("leisure", ""))
    print("\n=== üçΩÔ∏è ALIMENTA√á√ÉO ===\n")
    print(final_state.get("food", ""))
    print("\n=== ‚ú® RELAT√ìRIO FINAL ===\n")
    print(final_state.get("final", ""))

# ==========================
# Testes embutidos (sempre que RUN_TESTS=1)
# ==========================

def run_tests() -> None:
    print("Executando testes internos...")

    # 1) Valida√ß√£o de entradas
    ok, msg = validate_inputs("", "2025-01-01", "2025-01-02")
    assert not ok and msg, "Deveria falhar quando destino est√° vazio"

    ok, msg = validate_inputs("Porto", "2025-01-03", "2025-01-01")
    assert not ok and "t√©rmino" in (msg or "").lower(), "Deveria detectar data_fim < data_inicio"

    ok, msg = validate_inputs("Lisboa", "2025-01-01", "2025-01-03")
    assert ok, f"Valida√ß√£o deveria passar, msg: {msg}"

    # 2) Execu√ß√£o do grafo com DummyLLM
    dummy = DummyLLM()
    graph = build_graph(dummy)
    state_in: TripState = {
        "destino": "Lisboa, Portugal",
        "data_inicio": "2025-01-01",
        "data_fim": "2025-01-05",
        "orcamento": "R$ 5.000",
        "preferencias": "Museus e bairros hist√≥ricos",
    }
    state_out = graph.invoke(state_in)
    for k in ("plan", "hotels", "leisure", "food", "final"):
        assert state_out.get(k), f"Sa√≠da '{k}' n√£o foi preenchida"

    # 3) Smoke test com get_llm() sem GROQ_API_KEY (deve cair no DummyLLM)
    llm = get_llm(api_key=None)
    assert hasattr(llm, "invoke"), "LLM retornado deve ter m√©todo invoke()"

    print("‚úÖ Todos os testes passaram!")


if __name__ == "__main__":
    if os.environ.get("RUN_TESTS") == "1":
        run_tests()
    elif not STREAMLIT_AVAILABLE:
        run_cli()
    else:
        print(
            "Streamlit est√° dispon√≠vel. Execute a UI com: \n  streamlit run app.py\n"
        )
